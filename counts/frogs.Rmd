---
title: "Count Data Analysis Example"
author: "Scott Thompson"
date: "26/03/2022"
output: 
  pdf_document:
    citation_package: natbib
bibliography: frogs.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

* An analysis of over dispersed count data
* Uses frog road kill data described in chapter 16 of \cite{zuur2009mixed}
* association analysis

# Preliminaries

Start by loading libraries and data. Libraries first - we are using the tidyverse packages instead of the core R used in \cite{zuur2009mixed}.

```{r loadLibraries, message=FALSE, warning=FALSE}
library(readr)
library(dplyr)
library(stringr)
library(ggplot2)
library(gridExtra)
library(here)
```

Next we load in the data, it is not available directly from the git repository and must be grabbed separately from \url{http://highstat.com/index.php/mixed-effects-models-and-extensions-in-ecology-with-r}. Copyright status is unclear so it is excluded from repository. 

```{r loadData, message=FALSE, warning=FALSE, results=FALSE}
# specify the column types to minimise memory usage
# use column names to avoid creating column order dependency
ct <- cols(Sector = col_integer(), X = col_integer(), Y = col_integer(), 
           BufoCalamita = col_integer(), TOT.N = col_integer(), 
           S.RICH = col_integer(), 
           .default = col_double())
df <- read_tsv(here("data/RoadKills.txt"), col_types = ct) %>% 
  mutate(N.PATCH = as.integer(N.PATCH)) # if col_type is used will import as NA
assertthat::assert_that(nrow(df) == 52 && ncol(df) == 23, msg="Data set does match expect dimension 52 x 23")
rm(ct)
```
# Cleaning

The data has already been cleaned by the original authors. However the column names require more memory / cognitive capacity than I am willing to allocate, so we are adding a mapping to change the authors names to something I find easier to work with and at the same time creating a more descriptive text mapping that can be used for graphics. 

```{r makeMap, results=FALSE}
nameMap <- tibble(original = c("Sector", "X", "Y", "BufoCalamita", "TOT.N", "S.RICH",    "OPEN.L", "OLIVE", "MONT.S", "MONT", "POLIC", "SHRUB", "URBAN", "WAT.RES", "L.WAT.C", "L.D.ROAD", "L.P.ROAD", "D.WAT.RES", "D.WAT.COUR", "D.PARK", "N.PATCH", "P.EDGE",  "L.SDI"), 
                  feature = c('sector', 'x', 'y', 'bufoCalamita', 'count', 'sRich', 'openLands', 'oliveGroves', 'motadoShrubs', 'motadoNoShrubs', 'policulture', 'shrubs', 'urban', 'reservoirs', 'lenWaterCourses', 'lenDirtyRoad', 'lenPavedRoad', 'distReservoirs', 'distWaterCourses', 'distNationalPark', 'nHabitatPatches', 'edgesPerimeter', 'diversityIdx'), 
                  description = c('Sector', 'X coordinate', 'Y coordinate', 'BufoCalamita', 'Count of frog roadkill', 'S.Rich', 'Open Lands (ha)', 'Olive Groves (ha)', 'Motado with shrubs (ha)', 'Motado without shrubs (ha)', 'Policulture (ha)', 'Shrubs (ha)', 'Urban (ha)', 'Water reservoirs (ha)', 'Lenght of Water Courses (km)', 'Length of Dirty Road (km)', 'Len of Paved Road (km)', 'Distance to Water Reservoirs', 'Distance to Water Courses', 'Dist to National Park (m)', 'Number of Habitat Patches', 'Edges Perimeter', 'Landscape Shannon diversity index'))
```

We now change the column names to my preferred - this technique has the benefit of crashing if the column names in the data file do not match my pre-existing notation as encoded in the map.

```{r changeNames, results=FALSE}
# a name in the data file not in the map will not be found giving a shorter vector than required creating an error
names(df) <- nameMap %>% filter(names(df) %in% original) %>% pull(feature)
```
# Data description

There are 23 columns but only 17 features. Lets deal with the other columns. Sector is an identifier column for the sector along the road where the data is collected. X and Y refer to x, y coordinates for the midpoint of the sector and provide point spatial data for the data set - it should be noted that the counts are really for an area not a point. BufoCalamita is not described in the text but may be the count of the Natterjack toad (Bufo calamita) and TOT.N is the total number of road kill frogs counted for the sector. S.RICH is not known and was excluded in the original analysis; it is excluded here also.

The other columns are features and relate to the land around the road segment.

# Exploration

```{r univarPlots, message=FALSE, warning=FALSE}
# create a plot of each feature
dontPlot <- c('sector', 'x', 'y', 'bufoCalamita', 'sRich')
plotFeatures <- setdiff(names(df), dontPlot)
plotList <- lapply(plotFeatures, function(x, d) { 
                     ggplot(d, aes_string(x=x)) + 
                       geom_histogram() + 
                       labs(x = x) +
                       theme_minimal() }, df)
marrangeGrob(plotList, nrow=3, ncol=3)
```

From univariate plots, there are features with right skewness, urban, policulture, reservoirs, shrubs, motadoShrubs, oliveGroves, lenPavedRoad and nHabitatPatches. Transformation may be appropriate, log and square root transformations are common but these features include zero values precluding logarithms. 

Transform these variables using square root. 

```{r xform}
df <- df %>% mutate(urban = sqrt(urban), 
                    policulture = sqrt(policulture),
                    reservoirs = sqrt(reservoirs), 
                    shrubs = sqrt(shrubs),
                    motadoShrubs = sqrt(motadoShrubs), 
                    oliveGroves = sqrt(oliveGroves), 
                    lenPavedRoad  = sqrt(lenPavedRoad), 
                    nHabitatPatches = sqrt(nHabitatPatches))
```

Considering bi-variate plots of each feature against the frog counts, it is apparent that a linear model will be too restrictive. Generalised additive models include the ability to fit non-linear additive models through splines but at a cost of more complexity.

```{r bivarPlots, message=FALSE, warning=FALSE}
# create a plot of each features against the target (count)
dontPlot <- c('sector', 'x', 'y', 'bufoCalamita', 'count', 'sRich')
plotFeatures <- setdiff(names(df), dontPlot)
plotList <- lapply(plotFeatures, function(x, d) { 
                     ggplot(d, aes_string(x=x, y="count")) + 
                       geom_point() + 
                       geom_smooth() +
                       labs(x = x, y = "Road kill frog count") +
                       theme_minimal() }, df)
marrangeGrob(plotList, nrow=3, ncol=3)
```

```{r featuresToWorkWith, message=FALSE, warning=FALSE}
nFeaturesDesired = 5
```

# Feature selection

There are 17 features and 52 observations and given the non-linear nature suggested by the bi-variate plots it would be better to restrict the number of variables. Some alternatives are regularisation - lasso, ridge or glmnet, or feature selection. 

Here, we are using a technique from predictive modelling and allowing the data to indicate which features are more important. A scientific model should be based on a theoretical model of the principles underlying the system being examined. Selection based on variable importance derived from random forests is the technique used. Due to sample size we would prefer 5 or less features. We take the top 1 $--$ `r nFeaturesDesired` as the basis for models. 

```{r featureSelection, message=FALSE, warning=FALSE}
library(ranger)
library(purrr)
library(mgcv)

set.seed(1764)
rf <- ranger(count ~ ., data = df %>% select(any_of(c(plotFeatures, 'count'))),
             importance = "impurity", num.trees = 200)
importOrder <- names(importance(rf) |> sort(decreasing = TRUE))
form <- function(nfeatures, initStr = "", fnames, endStr = "") {
  str_c(initStr, str_c("s(", fnames[1:nfeatures], ")", collapse = " + "), endStr) |>
    formula()
}
```

Now create a data frame with the formula and GAM based on the importance order, models only consider main effects. 

```{r fitModels}
fits <- tibble(nf = 1:nFeaturesDesired) %>% 
  mutate(fitFormula = map(nf, form, initStr="count ~ ", fnames=importOrder)) %>% 
  mutate(model = map(fitFormula, gam, family=poisson(), data=df)) 
```

# Feature selection

Model selection based on the work in \cite{burnham2002model}. Here evidence ratios are used to select between models resulting in the "best" model being the one with 5 features, `r as.character(fits %>% filter(nf==5) %>% pull(fitFormula))`

```{r modelSelection, results='asis'}
fits <- fits %>% 
  mutate(aic = map_dbl(model, AIC)) %>% 
  mutate(aicDiff = aic - min(aic), 
         likelihood = exp(-0.5*aicDiff),
         weight = likelihood / sum(likelihood),
         evidenceRatio = max(weight) / weight) 
fits %>% 
  arrange(evidenceRatio) %>% 
  rename(n = nf) %>% 
  mutate(formula = as.character(fitFormula)) %>% 
  select(n, formula, aic, aicDiff, likelihood, weight, evidenceRatio) %>% 
  knitr::kable(digits = 2)
```
